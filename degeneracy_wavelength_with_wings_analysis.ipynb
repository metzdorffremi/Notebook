{
 "metadata": {
  "name": "",
  "signature": "sha256:b5b446700d5e3ed667c057e495b6f24108a5d80d55fc5a2071b6440481d242cb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#degeneracy analysis\n",
      "from __future__ import division\n",
      "from pyinstruments import CurveDB\n",
      "from users.remi import finesse\n",
      "import time\n",
      "import gc\n",
      "import operator\n",
      "\n",
      "#parent_curve: the curve that gathers the entire run\n",
      "#sub_parent_curve: the curve that collect the acquisitions for one wavelength\n",
      "#acquisition: one acquisition for one step and one wavelength\n",
      "#peak: one of the resonance peak in an acqisition\n",
      "\n",
      "#parent curve pk\n",
      "#parent_pk = 174230 #tests\n",
      "parent_pk = 175476\n",
      "parent_curve = CurveDB.objects.get(pk = parent_pk)\n",
      "sb_freq = parent_curve.childs.first().childs.first().params[\"sb_freq\"]\n",
      "step_length = 622e-9"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#save summary for all curves\n",
      "parent_curve = CurveDB.objects.get(pk = parent_pk)\n",
      "for sub_parent_curve in parent_curve.childs.all():\n",
      "    for c in sub_parent_curve.childs.all():\n",
      "        finesse.analyze_save_summary(c.pk)\n",
      "        gc.collect()\n",
      "        #print \"curve\", c.pk, \"fitted\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#add the correct mode number as a parameter for each peak (running time: 11s per sub_parent)\n",
      "t0 = time.clock()\n",
      "parent_curve = CurveDB.objects.get(pk = parent_pk)\n",
      "for sub_parent_curve in parent_curve.childs.all():\n",
      "    print \"treatment of curve\", sub_parent_curve.pk\n",
      "    for acquisition in sub_parent_curve.childs.filter(_name__contains='degeneracy_'):\n",
      "        FSRScan_acquisition = finesse.FSRScan(acquisition.pk)\n",
      "        peaks = finesse.DataPeaks(FSRScan_acquisition)\n",
      "        #print \"\\ttreatment of acquisition\", acquisition.pk\n",
      "        for i, peak in enumerate(acquisition.childs.all()[1:]):\n",
      "            peak.params[\"mode_number\"] = peaks.mode_number[i]\n",
      "            peak.save()\n",
      "print time.clock()-t0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "treatment of curve 175477\n",
        "treatment of curve"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 175520\n",
        "treatment of curve"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 175620\n",
        "treatment of curve"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 175663\n",
        "treatment of curve"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 175882\n",
        "treatment of curve"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 176313\n",
        "treatment of curve"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 176377\n",
        "treatment of curve"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 176462\n",
        "treatment of curve"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 177120\n",
        "treatment of curve"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 178883\n",
        "treatment of curve"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 179616\n",
        "129.724627438"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Determine approximatively the degeneracy length for each wavelength\n",
      "#Create the lists wavelengths, l_degs, slopes and y0s\n",
      "#   wavelengths: list that contains the wavelengths used for the acquisitions (len(wavelengths)=11 for curve 175476)\n",
      "#   l_degs: list that contains an estimation of the degeneracy length for each wavelength\n",
      "#   slopes, y0s: lists that contain the fit parameters to have the link between stepper_pos and length for each wavelength \n",
      "parent_curve = CurveDB.objects.get(pk = parent_pk)\n",
      "\n",
      "length_vs_step_curve = CurveDB()\n",
      "length_vs_step_curve.name = \"length_vs_step_for_analysis_of_\"+str(parent_curve.pk)\n",
      "length_vs_step_curve.save()\n",
      "\n",
      "wavelengths, l_degs, slopes, y0s = [], [], [], []\n",
      "acquisition_lengths = []\n",
      "acquisition_steps = []\n",
      "for sub_parent_curve in parent_curve.childs.all():\n",
      "    acquisition_lengths.append([])\n",
      "    acquisition_steps.append([])\n",
      "    wavelengths.append(sub_parent_curve.params[\"wavelength\"])\n",
      "    for acquisition in sub_parent_curve.childs.all():\n",
      "        acquisition_lengths[-1].append(acquisition.params[\"length\"])\n",
      "        acquisition_steps[-1].append(acquisition.params[\"stepper_pos\"])\n",
      "    c = CurveDB.create(acquisition_steps[-1], acquisition_lengths[-1])\n",
      "    c.name = \"length_vs_step_at_\"+str(wavelengths[-1])\n",
      "    c.save()\n",
      "    length_vs_step_curve.add_child(c)\n",
      "    fitcurve = c.fit(\"linear_with_known_slope\", autosave=True)\n",
      "    slope, y0 = -622e-9, fitcurve.params[\"y0\"]\n",
      "    del c\n",
      "    del fitcurve\n",
      "    l_degs.append(slope*sub_parent_curve.params[\"pos_deg\"] + y0)\n",
      "    slopes.append(slope)\n",
      "    y0s.append(y0)\n",
      "del acquisition_lengths\n",
      "del acquisition_steps\n",
      "print len(wavelengths), wavelengths\n",
      "print len(l_degs), mean(l_degs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "11 [1065.9, 1066, 1066.1, 1066.2, 1066.3, 1066.4, 1066.5, 1066.6, 1066.7, 1066.8, 1066.9]\n",
        "11 0.000547313643639\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot finesse vs length with a different color for each wavelength to have a very first idea (running time: <1s)\n",
      "parent_curve = CurveDB.objects.get(pk = parent_pk)\n",
      "\n",
      "steps, lengths, finesses = [], [], []\n",
      "for i, sub_parent_curve in enumerate(parent_curve.childs.all()):\n",
      "    sub_parent_curve.params[\"wavelength\"] = sub_parent_curve.childs.first().params[\"wavelength\"]\n",
      "    steps.append([])\n",
      "    lengths.append([])\n",
      "    finesses.append([])\n",
      "    for acquisition in sub_parent_curve.childs.filter(_name__contains='degeneracy_'):\n",
      "        steps[-1].append(acquisition.params[\"stepper_pos\"])\n",
      "        lengths[-1].append(acquisition.params[\"length\"])\n",
      "        finesses[-1].append(acquisition.params[\"finesse\"])\n",
      "        del acquisition\n",
      "    plot(array(steps[i])*slopes[i]+y0s[i], finesses[i], '.')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 297
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot bandwidth vs length without any effort to properly stack the curves obtained for different wavelengths\n",
      "parent_curve = CurveDB.objects.get(pk = parent_pk)\n",
      "\n",
      "lengths, bandwidths = [], []\n",
      "for i, sub_parent_curve in enumerate(parent_curve.childs.all()):\n",
      "    lengths.append([])\n",
      "    bandwidths.append([])\n",
      "    for acquisition in sub_parent_curve.childs.filter(_name__contains='degeneracy_'):\n",
      "        pos_deg = sub_parent_curve.params[\"pos_deg\"]\n",
      "        for peak in acquisition.childs.all()[1:]:\n",
      "            stepper_length = (acquisition.params[\"stepper_pos\"] - pos_deg)*step_length + l_degs[i]\n",
      "            length = stepper_length + peak.params[\"pzt_pos\"]\n",
      "            lengths[i].append(length)\n",
      "            bandwidths[i].append(peak.childs.first().params[\"relative_bandwidth\"]*sb_freq*2)\n",
      "    #plot(lengths[i], bandwidths[i], '.')\n",
      "#for i_plot in range(len(lengths)):\n",
      "#    figure(i_plot+1)\n",
      "#    plot(lengths[i_plot], bandwidths[i_plot], '.', label=\"raw data\")\n",
      "xlabel(\"length\")\n",
      "ylabel(\"bandwidth\")\n",
      "grid('on')\n",
      "legend()\n",
      "    #plot(lengths[i], 3e8/(2*array(lengths[i]))/array(bandwidths[i]), '.') #finesse"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\matplotlib\\axes.py:4747: UserWarning: No labeled objects found. Use label='...' kwarg on individual plots.\n",
        "  warnings.warn(\"No labeled objects found. \"\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:py.warnings:C:\\Python27\\lib\\site-packages\\matplotlib\\axes.py:4747: UserWarning: No labeled objects found. Use label='...' kwarg on individual plots.\n",
        "  warnings.warn(\"No labeled objects found. \"\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot bandwidth vs length after a naive folding of the acquisitions to gather the peaks that correspond to the same resonance\n",
      "parent_curve = CurveDB.objects.get(pk = parent_pk)\n",
      "\n",
      "step_length = 622e-9 #cf workbook\n",
      "lengths , bandwidths, mode_numbers, peak_depths = [], [], [], []\n",
      "for i, sub_parent_curve in enumerate(parent_curve.childs.all()):\n",
      "    print sub_parent_curve.pk\n",
      "    lengths.append([])\n",
      "    bandwidths.append([])\n",
      "    mode_numbers.append([])\n",
      "    peak_depths.append([])\n",
      "    for j, acquisition in enumerate(sub_parent_curve.childs.filter(_name__contains='degeneracy_')):\n",
      "        #print sub_parent_curve.pk\n",
      "        pos_deg = sub_parent_curve.params[\"pos_deg\"]\n",
      "        FSRScan_parent = finesse.FSRScan(acquisition.pk)\n",
      "        acquisition_mode_numbers = finesse.DataPeaks(FSRScan_parent).mode_number\n",
      "        represented_mode_numbers = sorted(set(acquisition_mode_numbers))\n",
      "        for mode_number in represented_mode_numbers:\n",
      "            mean_length, mean_bandwidth, mean_peak_depth = [], [], []\n",
      "            for peak in acquisition.childs.all()[1:]:\n",
      "                if peak.params[\"mode_number\"] == mode_number:\n",
      "                    stepper_length = (acquisition.params[\"stepper_pos\"] - pos_deg)*step_length + l_degs[i]\n",
      "                    length = stepper_length + peak.params[\"pzt_pos\"]\n",
      "                    bandwidth = peak.childs.first().params[\"relative_bandwidth\"]*sb_freq*2\n",
      "                    peak_depth = abs(peak.childs.first().params[\"scale\"])\n",
      "                    mean_length.append(length)\n",
      "                    mean_bandwidth.append(bandwidth)\n",
      "                    mean_peak_depth.append(peak_depth)\n",
      "            lengths[i].append(mean(mean_length))\n",
      "            bandwidths[i].append(mean(mean_bandwidth))\n",
      "            peak_depths[i].append(mean(mean_peak_depth))\n",
      "            p = mode_number + j #Naive version\n",
      "            mode_numbers[i].append(p)\n",
      "    #plot(lengths[i], bandwidths[i], '.')\n",
      "#plot(mode_numbers[0], peak_depths[0])\n",
      "for i_plot in range(len(lengths)):\n",
      "    figure(i_plot+1)\n",
      "    plot(lengths[i_plot], bandwidths[i_plot], '.', label=\"dumb folded acquisitions\")\n",
      "legend()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "175477\n",
        "175520"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "175620"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "175663"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "175882"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "176313"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "176377"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "176462"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "177120"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "178883"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "179616"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "<matplotlib.legend.Legend at 0x4e367430>"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Prepare the lists before manual folding\n",
      "parent_curve = CurveDB.objects.get(pk = parent_pk)\n",
      "\n",
      "step_length = 622e-9 #cf workbook\n",
      "lengths , bandwidths = [], []\n",
      "mode_number_acquisitions, peak_depth_acquisitions = [], []\n",
      "length_acquisitions, bandwidth_acquisitions = [],[]\n",
      "for i, sub_parent_curve in enumerate(parent_curve.childs.all()):\n",
      "    print sub_parent_curve.pk\n",
      "    mode_number_acquisitions.append([])\n",
      "    peak_depth_acquisitions.append([])\n",
      "    length_acquisitions.append([])\n",
      "    bandwidth_acquisitions.append([])\n",
      "    for j, acquisition in enumerate(sub_parent_curve.childs.filter(_name__contains='degeneracy_')):\n",
      "        pos_deg = sub_parent_curve.params[\"pos_deg\"]\n",
      "        FSRScan_parent = finesse.FSRScan(acquisition.pk)\n",
      "        acquisition_mode_numbers = finesse.DataPeaks(FSRScan_parent).mode_number\n",
      "        represented_mode_numbers = sorted(set(acquisition_mode_numbers))\n",
      "        mode_number_acquisitions[i].append([])\n",
      "        peak_depth_acquisitions[i].append([])\n",
      "        length_acquisitions[i].append([])\n",
      "        bandwidth_acquisitions[i].append([])\n",
      "        for mode_number in represented_mode_numbers:\n",
      "            mean_length, mean_bandwidth, mean_peak_depth = [], [], []\n",
      "            for peak in acquisition.childs.all()[1:]:\n",
      "                if peak.params[\"mode_number\"] == mode_number:\n",
      "                    stepper_length = (acquisition.params[\"stepper_pos\"] - pos_deg)*step_length + l_degs[i]\n",
      "                    length = stepper_length + peak.params[\"pzt_pos\"]\n",
      "                    bandwidth = peak.childs.first().params[\"relative_bandwidth\"]*sb_freq*2\n",
      "                    peak_depth = abs(peak.childs.first().params[\"scale\"])\n",
      "                    mean_length.append(length)\n",
      "                    mean_bandwidth.append(bandwidth)\n",
      "                    mean_peak_depth.append(peak_depth)\n",
      "            length_acquisitions[i][j].append(mean(mean_length))\n",
      "            bandwidth_acquisitions[i][j].append(mean(mean_bandwidth))\n",
      "            peak_depth_acquisitions[i][j].append(mean(mean_peak_depth))\n",
      "            p = mode_number + j #Naive version\n",
      "            mode_number_acquisitions[i][j].append(p)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "175477\n",
        "175520"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "175620"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "175663"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "175882"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "176313"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "176377"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "176462"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "177120"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "178883"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "179616"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_mode_numbers = []\n",
      "for acquisitions in mode_number_acquisitions:\n",
      "    new_mode_numbers.append([])\n",
      "    for modes in acquisitions:\n",
      "        new_mode_numbers[-1].append([])\n",
      "        new_mode_numbers[-1][-1] = list(modes)\n",
      "#figure(1)\n",
      "#for i in range(len(mode_number_acquisitions[curve])):\n",
      "#    plot(new_mode_numbers[curve][i], peak_depth_acquisitions[curve][i])\n",
      "\n",
      "def common_elements(l1, l2):\n",
      "    \"\"\"return the list containing the common elements to l1 and l2 and\n",
      "    the index for each common_element of that element in l1 and l2\"\"\"\n",
      "    l_com, index1, index2 = [], [], []\n",
      "    for i, item1 in enumerate(l1):\n",
      "        for j, item2 in enumerate(l2):\n",
      "            if item2 == item1:\n",
      "                l_com.append(item1)\n",
      "                index1.append(i)\n",
      "                index2.append(j)\n",
      "    return l_com, index1, index2\n",
      "\n",
      "#Detect stacking errors\n",
      "def find_stacking_errors(modes, peak_depths):\n",
      "    errors = []\n",
      "    for i in range(len(modes)):\n",
      "        #print \"Checking portion:\", i\n",
      "        if i>0:\n",
      "            common_mode_numbers, index_old, index_new = common_elements(modes[i-1], modes[i])\n",
      "            deltas = []\n",
      "            delta_modes = []\n",
      "            for j in range(len(common_mode_numbers)):\n",
      "                deltas.append(peak_depths[i][index_new[j]] - peak_depths[i-1][index_old[j]])\n",
      "                delta_modes.append(mode_number_acquisitions[curve][i][index_new[j]] - mode_number_acquisitions[curve][i-1][index_old[j]])\n",
      "            if abs(mean(deltas)) > 0.01:\n",
      "                #print \"\\tSTACKING ERROR for curve portion\", i\n",
      "                errors.append([i, mean(deltas)])\n",
      "            else:\n",
      "                None#print \"\\tOK\" \n",
      "    return errors\n",
      "#print \"find_stacking_errors test\"\n",
      "#print find_stacking_errors(new_mode_numbers[curve], peak_depth_acquisitions[curve])\n",
      "\n",
      "#Repare stacking errors\n",
      "def fixe_stacking_errors(modes, peak_depths):\n",
      "    for count in range(20):\n",
      "        errors = find_stacking_errors(modes, peak_depths)\n",
      "        #print errors\n",
      "        if len(errors) == 0:\n",
      "            print \"JOB DONE\"\n",
      "            break\n",
      "        error = errors[0]\n",
      "        if (error[0]<5) and (error[1]>0):\n",
      "            #print \"\\tcase 1\"\n",
      "            mode_cor = -1      #don't touch\n",
      "        elif (error[0]<5) and (error[1]<0):\n",
      "            #print \"\\tcase 2\"\n",
      "            mode_cor = 1\n",
      "        elif (error[0]>5) and (error[1]>0):\n",
      "            #print \"\\tcase 3\"\n",
      "            mode_cor = 1       #don't touch\n",
      "        elif (error[0]>5) and (error[1]<0):\n",
      "            #print \"\\tcase 4\"\n",
      "            mode_cor = -1\n",
      "        else:\n",
      "            #print \"\\tspecial case\"\n",
      "            mode_cor = 1\n",
      "        modes[error[0]] = list(array(modes[error[0]])+mode_cor)\n",
      "    return modes\n",
      "\n",
      "print \"fixe_stacking_errors test\"\n",
      "for curve in range(len(new_mode_numbers)):\n",
      "    print \"stacking curve\", curve\n",
      "    fixe_stacking_errors(new_mode_numbers[curve], peak_depth_acquisitions[curve])\n",
      "    \n",
      "#figure(2)\n",
      "#for i in range(len(mode_number_acquisitions[curve])):\n",
      "#    plot(new_mode_numbers[curve][i], peak_depth_acquisitions[curve][i], label=i)\n",
      "#legend()\n",
      "\n",
      "ploting = False\n",
      "if ploting == True:\n",
      "    for curve in range(len(new_mode_numbers)):\n",
      "        figure(curve+1)\n",
      "        for i in range(len(mode_number_acquisitions[curve])):\n",
      "            plot(new_mode_numbers[curve][i], peak_depth_acquisitions[curve][i])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "fixe_stacking_errors test\n",
        "stacking curve 0\n",
        "JOB DONE\n",
        "stacking curve 1\n",
        "JOB DONE\n",
        "stacking curve 2\n",
        "JOB DONE\n",
        "stacking curve 3\n",
        "JOB DONE\n",
        "stacking curve 4\n",
        "JOB DONE\n",
        "stacking curve 5\n",
        "JOB DONE\n",
        "stacking curve 6\n",
        "JOB DONE\n",
        "stacking curve 7\n",
        "JOB DONE\n",
        "stacking curve 8\n",
        "JOB DONE\n",
        "stacking curve 9\n",
        "JOB DONE\n",
        "stacking curve 10\n",
        "JOB DONE\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Fold the acquisitions to gather resonances with the same mode number with the modes manualy corrected\n",
      "corrected_mode_numbers, corrected_lengths, corrected_bandwidths = [], [], []\n",
      "folded_mode_numbers, folded_lengths, folded_bandwidths = [],[],[]\n",
      "for curve in range(len(new_mode_numbers)):\n",
      "    corrected_mode_numbers.append([])\n",
      "    corrected_lengths.append([])\n",
      "    corrected_bandwidths.append([])\n",
      "    folded_mode_numbers.append([])\n",
      "    folded_lengths.append([])\n",
      "    folded_bandwidths.append([])\n",
      "    for ps, ls, bs in zip(new_mode_numbers[curve], length_acquisitions[curve], bandwidth_acquisitions[curve]):\n",
      "        for p, l, b in zip(ps, ls, bs):\n",
      "            corrected_mode_numbers[curve].append(p)\n",
      "            corrected_lengths[curve].append(l)\n",
      "            corrected_bandwidths[curve].append(b)\n",
      "    \n",
      "    #Folding the lists\n",
      "    represented_mode_numbers = sorted(set(corrected_mode_numbers[curve]))\n",
      "    for mode in represented_mode_numbers:\n",
      "        mean_length, mean_bandwidth = [],[]\n",
      "        for i, p, l, b in zip(range(len(corrected_mode_numbers[curve])), corrected_mode_numbers[curve],\n",
      "                              corrected_lengths[curve], corrected_bandwidths[curve]):\n",
      "            if p == mode:\n",
      "                mean_length.append(l)\n",
      "                mean_bandwidth.append(b)\n",
      "        folded_mode_numbers[curve].append(p)\n",
      "        folded_lengths[curve].append(mean(mean_length))\n",
      "        folded_bandwidths[curve].append(mean(mean_bandwidth))        \n",
      "#plot(corrected_mode_numbers[0], corrected_lengths[0], '.')\n",
      "\n",
      "ploting = False\n",
      "if ploting == True:\n",
      "    for curve in range(len(new_mode_numbers)):\n",
      "        figure(curve+1)\n",
      "        plot(folded_lengths[curve], folded_bandwidths[curve])\n",
      "#plot(folded_lengths[0], folded_bandwidths[0], '.', label=\"careful folded acquisitions\")\n",
      "#legend(loc='best')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#More precise determination of the degeneracy length\n",
      "results_curve = CurveDB()\n",
      "results_curve.name = \"analysis_degeneracy_curve_\"+str(parent_curve.pk)\n",
      "results_curve.save()\n",
      "\n",
      "primary_results_curve = CurveDB()\n",
      "primary_results_curve.name = \"primary_results\"\n",
      "primary_results_curve.save()\n",
      "results_curve.add_child(primary_results_curve)\n",
      "\n",
      "new_l_degs = []\n",
      "\n",
      "for curve in range(len(folded_lengths)):\n",
      "    c = CurveDB.create(folded_lengths[curve], folded_bandwidths[curve])\n",
      "    c.name = \"degeneracy_for_wavelength_\"+str(wavelengths[curve])\n",
      "    c.params[\"wavelength\"] = wavelengths[curve]\n",
      "    c.save()\n",
      "    primary_results_curve.add_child(c)\n",
      "    fitcurve = c.fit(\"lorentz\", autosave=True)\n",
      "    new_l_degs.append(fitcurve.params[\"x0\"])\n",
      "    del c\n",
      "    del fitcurve\n",
      "\n",
      "for curve in range(len(folded_lengths)):\n",
      "    offset = mean(new_l_degs)-new_l_degs[curve]\n",
      "    figure(1)\n",
      "    title(\"before stacking\")\n",
      "    plot(folded_lengths[curve], folded_bandwidths[curve])\n",
      "    figure(2)\n",
      "    title(\"after stacking\")\n",
      "    plot(array(folded_lengths[curve])+offset, folded_bandwidths[curve])\n",
      "print mean(new_l_degs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.000548595033962\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plot the ultimate curve\n",
      "corrected_results_curve = CurveDB()\n",
      "corrected_results_curve.name = \"corrected_results\"\n",
      "corrected_results_curve.save()\n",
      "results_curve.add_child(corrected_results_curve)\n",
      "\n",
      "new_folded_lengths = []\n",
      "for curve in range(len(folded_lengths)):\n",
      "    offset = mean(new_l_degs)-new_l_degs[curve]\n",
      "    new_folded_lengths.append(list(array(folded_lengths[curve])+offset))\n",
      "    \n",
      "total_lengths = []\n",
      "total_bandwidths = []\n",
      "for ls, bs in zip(new_folded_lengths, folded_bandwidths):\n",
      "    for l, b in zip(ls, bs):\n",
      "        total_lengths.append(l)\n",
      "        total_bandwidths.append(b)\n",
      "sorted_list = []\n",
      "for l, b in zip(total_lengths, total_bandwidths):\n",
      "    sorted_list.append([l, b])\n",
      "sorted_list = sorted(sorted_list, key=operator.itemgetter(0), reverse = True)\n",
      "for i, lb in enumerate(sorted_list):\n",
      "    total_lengths[i] = lb[0]\n",
      "    total_bandwidths[i] = lb[1]\n",
      "plot(total_lengths, total_bandwidths)\n",
      "\n",
      "c = CurveDB.create(total_lengths, total_bandwidths)\n",
      "c.name = \"bandwidth_vs_length\"\n",
      "c.save()\n",
      "corrected_results_curve.add_child(c)\n",
      "c = CurveDB.create(total_lengths, 3e8/(2*array(total_lengths))/array(total_bandwidths))\n",
      "c.name = \"finesse_vs_length\"\n",
      "c.save()\n",
      "corrected_results_curve.add_child(c)\n",
      "c = CurveDB.create(total_lengths, 2*np.pi/(3e8/(2*array(total_lengths))/array(total_bandwidths)))\n",
      "c.name = \"T+P_vs_length\"\n",
      "c.save()\n",
      "corrected_results_curve.add_child(c)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "parent_curve = CurveDB.objects.get(pk = parent_pk)\n",
      "\n",
      "step_length = 622e-9 #cf workbook\n",
      "sb_freq = parent_curve.childs.first().childs.first().params[\"sb_freq\"]\n",
      "lengths , bandwidths, mode_numbers, wavelengths = [], [], [], []\n",
      "for i, sub_parent_curve in enumerate(parent_curve.childs.all()):\n",
      "    lengths.append([])\n",
      "    bandwidths.append([])\n",
      "    mode_numbers.append([])\n",
      "    wavelengths.append(sub_parent_curve.childs.first().params[\"wavelength\"])\n",
      "    for j, acquisition in enumerate(sub_parent_curve.childs.all()):\n",
      "        central_stepper_pos = sub_parent_curve.childs.all()[int(len(sub_parent_curve.childs.all())/2)].params['stepper_pos']\n",
      "        FSRScan_parent = finesse.FSRScan(acquisition.pk)\n",
      "        acquisition_mode_numbers = finesse.DataPeaks(FSRScan_parent).mode_number\n",
      "        represented_mode_numbers = sorted(set(acquisition_mode_numbers))\n",
      "        for mode_number in represented_mode_numbers:\n",
      "            mean_length, mean_bandwidth = [], []\n",
      "            for peak in acquisition.childs.all()[1:]:\n",
      "                if peak.params[\"mode_number\"] == mode_number:\n",
      "                    if j<=6:\n",
      "                        stepper_length = (acquisition.params[\"stepper_pos\"] - central_stepper_pos)*step_length + l_deg[0]\n",
      "                    else:\n",
      "                        stepper_length = (acquisition.params[\"stepper_pos\"] - central_stepper_pos)*step_length + l_deg[1]\n",
      "                    #length = stepper_length + peak.params[\"pzt_pos\"]\n",
      "                    length = stepper_length + peak.params[\"pzt_pos2\"]\n",
      "                    bandwidth = peak.childs.first().params[\"relative_bandwidth\"]*sb_freq*2\n",
      "                    mean_length.append(length)\n",
      "                    mean_bandwidth.append(bandwidth)\n",
      "            mode_numbers[i].append(mode_number+j)\n",
      "            lengths[i].append(mean(mean_length))\n",
      "            bandwidths[i].append(mean(mean_bandwidth))\n",
      "\n",
      "for i in range(len(lengths)):\n",
      "    plot(lengths[i], bandwidths[i], '.')\n",
      "\n",
      "results_curve = CurveDB()\n",
      "#results_curve.name = \"analysis_degeneracy_curve_\"+str(parent_curve.pk)\n",
      "results_curve.name = \"analysis_degeneracy_with_new_pzt_pos_curve_\"+str(parent_curve.pk)\n",
      "results_curve.save()\n",
      "\n",
      "primary_results_curve = CurveDB()\n",
      "primary_results_curve.name = \"primary_results\"\n",
      "primary_results_curve.save()\n",
      "results_curve.add_child(primary_results_curve)\n",
      "\n",
      "corrected_results_curve = CurveDB()\n",
      "corrected_results_curve.name = \"corrected_results\"\n",
      "corrected_results_curve.save()\n",
      "results_curve.add_child(corrected_results_curve)\n",
      "\n",
      "raw_lengths, raw_bandwiths, raw_mode_numbers = list(lengths), list(bandwidths), list(mode_numbers)\n",
      "clear_lengths, clear_bandwidths, clear_mode_numbers = [], [], []\n",
      "\n",
      "for j in range(len(raw_lengths)):\n",
      "    clear_mode_numbers.append(set(mode_numbers[j]))\n",
      "    clear_lengths.append([])\n",
      "    clear_bandwidths.append([])\n",
      "    for clear_mode_number in clear_mode_numbers[j]:\n",
      "        clear_lengths[j].append([])\n",
      "        clear_bandwidths[j].append([])\n",
      "        for i, raw_mode_number in enumerate(raw_mode_numbers[j]):\n",
      "            if raw_mode_number == clear_mode_number:\n",
      "                clear_lengths[j][-1].append(raw_lengths[j][i])\n",
      "                clear_bandwidths[j][-1].append(raw_bandwiths[j][i])\n",
      "        clear_lengths[j][-1] = mean(clear_lengths[j][-1])\n",
      "        clear_bandwidths[j][-1] = mean(clear_bandwidths[j][-1])\n",
      "        figure(1)\n",
      "    sorted_list = []\n",
      "    for l, b in zip(clear_lengths[j], clear_bandwidths[j]):\n",
      "        sorted_list.append([l, b])\n",
      "    sorted_list = sorted(sorted_list, key=operator.itemgetter(0), reverse = True)\n",
      "    for i, lb in enumerate(sorted_list):\n",
      "        clear_lengths[j][i] = lb[0]\n",
      "        clear_bandwidths[j][i] = lb[1]\n",
      "    c = CurveDB.create(clear_lengths[j], clear_bandwidths[j])\n",
      "    c.name = \"degeneracy_for_wavelength_\"+str(wavelengths[j])\n",
      "    c.params[\"wavelength\"] = wavelengths[j]\n",
      "    c.save()\n",
      "    primary_results_curve.add_child(c)\n",
      "    fitcurve = c.fit(\"lorentz\", autosave=True)\n",
      "#After fitting the results by lorentz\n",
      "corrected_central_lengths = []\n",
      "for c in primary_results_curve.childs.all():\n",
      "    corrected_central_lengths.append(c.childs.first().params[\"x0\"])\n",
      "    del c\n",
      "\n",
      "corrected_lengths = []\n",
      "for i, l in enumerate(clear_lengths):\n",
      "    offset = corrected_central_lengths[i]-mean(l)\n",
      "    corrected_lengths.append(list(array(l)-offset))\n",
      "total_lengths, total_bandwidths = [], []\n",
      "for i in range(len(corrected_lengths)):\n",
      "    c = CurveDB.create(corrected_lengths[i], clear_bandwidths[i])\n",
      "    c.name = \"bandwidth_vs_corrected_length_at_\"+str(wavelengths[i])\n",
      "    c.save()\n",
      "    corrected_results_curve.add_child(c)\n",
      "    total_lengths += corrected_lengths[i]\n",
      "    total_bandwidths += clear_bandwidths[i]\n",
      "sorted_list = []\n",
      "for l, b in zip(total_lengths, total_bandwidths):\n",
      "    sorted_list.append([l, b])\n",
      "sorted_list = sorted(sorted_list, key=operator.itemgetter(0), reverse = True)\n",
      "for i, lb in enumerate(sorted_list):\n",
      "    total_lengths[i] = lb[0]\n",
      "    total_bandwidths[i] = lb[1]\n",
      "c = CurveDB.create(total_lengths, total_bandwidths)\n",
      "c.name = \"bandwidth_vs_length\"\n",
      "c.save()\n",
      "results_curve.add_child(c)\n",
      "c = CurveDB.create(total_lengths, 3e8/(2*array(total_lengths))/array(total_bandwidths))\n",
      "c.name = \"finesse_vs_length\"\n",
      "c.save()\n",
      "results_curve.add_child(c)\n",
      "c = CurveDB.create(total_lengths, 2*np.pi/(3e8/(2*array(total_lengths))/array(total_bandwidths)))\n",
      "c.name = \"T+P_vs_length\"\n",
      "c.save()\n",
      "results_curve.add_child(c)\n",
      "\n",
      "#for i in range(len(corrected_lengths)):\n",
      "#    plot(corrected_lengths[i], clear_bandwidths[i], '.')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Refining the pzt_pos parameter (running time: 7min)\n",
      "    #Add the parameter pzt_volt for each peak\n",
      "t0 = time.clock()\n",
      "\n",
      "delta_pzt_volt = []\n",
      "for sub_parent_curve in parent_curve.childs.all():\n",
      "    print sub_parent_curve.pk\n",
      "    for acquisition in sub_parent_curve.childs.all():\n",
      "        FSRS_acquisition = finesse.FSRScan(acquisition.pk)\n",
      "        peaks = FSRS_acquisition.curve.childs.filter(_name__contains='peak@')\n",
      "        old_pzt_volt = 0\n",
      "        slope = 0\n",
      "        for peak in peaks:\n",
      "            DP_peak = finesse.DataPeaks(FSRS_acquisition)\n",
      "            pzt_volt = DP_peak.pzt_volt(peak.childs.first().params[\"x0\"])\n",
      "            peak.params[\"pzt_volt\"] = pzt_volt\n",
      "            peak.save()\n",
      "            if (peak.params[\"slope\"]-slope) <> 0:\n",
      "                delta_pzt_volt.append([])\n",
      "                old_pzt_volt = pzt_volt\n",
      "                slope = peak.params[\"slope\"]\n",
      "            else:\n",
      "                delta_pzt_volt[-1].append(abs(pzt_volt-old_pzt_volt))\n",
      "                old_pzt_volt = pzt_volt\n",
      "\n",
      "#new estimation for piezo_meterspervolt parameter\n",
      "delta_pzt = []\n",
      "for deltas in delta_pzt_volt:\n",
      "    if len(deltas) <> 0:\n",
      "        delta_pzt.append(mean(deltas))\n",
      "meters_per_volt = 1066e-9/2 / mean(delta_pzt)\n",
      "print \"Meters per (100)Volt coefficient:\", meters_per_volt\n",
      "\n",
      "print time.clock()-t0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "166125\n",
        "166148"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "166696"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "167075"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "167374"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "167820"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "167843"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "167866"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "167889"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "167912"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "169061"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "169338"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "169694"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "170086"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "170476"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "170978"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "171260"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "171613"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "172248"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "172724"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "172747"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Meters per (100)Volt coefficient:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3.06417926596e-07\n",
        "419.686930089\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Refining the pzt_pos parameter (running time: 80s)\n",
      "    #Add the parameter pzt_pos2 for each peak\n",
      "t0 = time.clock()\n",
      "\n",
      "for sub_parent_curve in parent_curve.childs.all():\n",
      "    print sub_parent_curve.pk\n",
      "    for acquisition in sub_parent_curve.childs.all():\n",
      "        for peak in acquisition.childs.filter(_name__contains='peak@'):\n",
      "            pzt_pos2 = peak.params[\"pzt_volt\"]*meters_per_volt\n",
      "            peak.params[\"pzt_pos2\"] = peak.params[\"pzt_volt\"]*meters_per_volt\n",
      "            peak.save()\n",
      "\n",
      "print time.clock()-t0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "166125\n",
        "166148"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "166696"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "167075"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "167374"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "167820"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "167843"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "167866"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "167889"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "167912"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "169061"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "169338"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "169694"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "170086"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "170476"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "170978"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "171260"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "171613"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "172248"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "172724"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "172747"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "79.226486272"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot(lengths[0], bandwidths[0], '.')\n",
      "plot(lengths[1], bandwidths[1], '.')\n",
      "plot(lengths[10], bandwidths[10], '.')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 94,
       "text": [
        "[<matplotlib.lines.Line2D at 0x494ae8f0>]"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(len(lengths)):\n",
      "    figure(i+1)\n",
      "    plot(lengths[i], bandwidths[i], '.')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Python27\\lib\\site-packages\\matplotlib\\pyplot.py:412: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_num_figures`).\n",
        "  max_open_warning, RuntimeWarning)\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:py.warnings:C:\\Python27\\lib\\site-packages\\matplotlib\\pyplot.py:412: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_num_figures`).\n",
        "  max_open_warning, RuntimeWarning)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(clear_mode_numbers), len(clear_lengths), len(clear_bandwidths)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 21 21 21\n"
       ]
      }
     ],
     "prompt_number": 221
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean(array([1,2]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 284,
       "text": [
        "1.5"
       ]
      }
     ],
     "prompt_number": 284
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c = CurveDB.objects.get(pk=173669)\n",
      "fit = CurveDB.objects.get(pk=173674)\n",
      "plot(c.data.index*1e6, c.data.values*1e6, label=\"$\\mathrm{data}$\")\n",
      "plot(fit.data.index*1e6, fit.data.values*1e6, label=\"$\\mathrm{lorentz\\ fit}$\")\n",
      "xlabel(\"$\\mathrm{Cavity\\ length\\ (\\mu m)}$\")\n",
      "ylabel(\"$\\mathrm{T+P\\ (ppm)}$\")\n",
      "legend(loc='best')\n",
      "grid('on')\n",
      "savefig('losses_vs_length_for TEM00-TEM04_degeneracy.pdf', bbox_inches='tight')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd Documents/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\Remi\\Documents\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}